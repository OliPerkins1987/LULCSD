---
title: "experiment"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{experiment}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(rhapsody)

```

Load the sd model defined in the model vignette

```

### load model object
sd.mod <- init_model(stocks_from_key(s_key), flows_from_key(f_key),inputs_from_key(i_key, path = paste0(getwd(), '/data')), outputs_from_key(o_key), parameter_list = list(p_land_trans = 0.0005, p_price_update= 0.05), initial_stock_vals = start_vals, run = list(nsteps = 31, step = 1990), load_stock_dat = F)

### load flow functions
source(paste0(getwd(), '/data/example_flows.R'))

```

Now, let's build an experiment to define our parameter ranges against observations


```

Priors <- data.frame(p_land_trans = runif(1000, 0.00001, 0.001), p_price_update = runif(1000, 0.01, 0.1))
sd.exp <- Experiment(sd.mod, Priors, start_vals, nrow(Priors))


```

Now, let's run the experiment and define our posterior parameter ranges against observations


```

sd.exp     <- run_experiment(sd.exp)

### make some fake historical observations

dat   <- data.frame(soybean_area = seq(1000, 500000, by = (500000-1000)/30), forest_area = seq(1000000, 500000, by = 0-(500000/30)))
noise <- sapply(seq(1000, 500000, by = (500000-1000)/30), function(z) {rnorm(1, z, z/3)})
dat$soybean_area <- dat$soybean_area + noise
dat$forest_area  <- dat$forest_area - noise


### filter the parameters based on their fit to the observations
result <- select_pars(sd.exp, data = dat, method = 'best', .frac = 0.01, .scale = T,
          .subset = sapply(sd.exp@mod@outputs, function(z) {z@o_name})[c(1:2)])

### look at the results
summary(Priors)
summary(Priors[result$runs, ])

### visually check model outputs
plot(unlist(sd.exp@results[[as.numeric(result$runs[1])]][[1]]@o_outputs), dat$soybean_area)
abline(0, 1)

```
